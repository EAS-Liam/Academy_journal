    Task 4 is to automate the process of the previous task with bash scripts.

    First thing we did was capture all of the config and setup files that needed to be editied during the process of seting up the different services.
    With the config files captured we needed to make sure we had all the commands that needed to be run for each role.
    With our Academy Journals we had these already captured.

    Next it was onto planning and writing each individual script.
    My main priority was the Master-Script but I was also collaborating to help write up the other scripts too.

    Planning and writing the DHCP script was done by Harrision with assistance from me and using my Academy Journal write up for the commands and their order.
    
    Planning and writing the Master-Script is the main task I have.
    This script will prompt the user for what they want to set the system it is run on to do asking for Gateway, DHCP or DNS.
    It will then take the users input and will pull down the required script from github and execute that script.

    At this stage after the first day the DHCP script has been written by Harrison (some alterations may need to be made) and the Master-Script has the bare bones structure of running bash files and ssh hopping.

    Before proceeding with the rest of the master script we decided to run some tests on the individual scripts.

    Starting out I reset the vms back to their initial snapshot and then had to setup the network adapters for the ingress and egress systems.

    With those set we had vms set back to their initial state ready for our script testing.

    We were able to ssh into Kaines vm and then from there could clone the repo containing our scripts.
    We then ran the command
ssh root@192.168.1.175 < dhcp.conf
    This command will tell the system to run the bash file on the supplied ssh system instead of running it on the local system.
    
    From this point we could see that in general our script seemed to be running well and was correctly creating and populating the config files with the correct data however we ran into the issue that the dnf and yum package managers were down so at this point we were unable to test downloading and running the services.
    This we will now pick up tomorrow when hopefully those paclage managers are back up.

    After coming back the next day the dnf package manager was up and running again so we could start testing our scripts.

ssh root@192.168.1.175 < dhcp.sh
    We first tested the dhcp script and after ironing out a few directory typos such as looking for network-script instead of network-scripts then we were able to confirm that the dhcp.sh script worked exactly as intended.


    We next decided to try testing the gateway scrip. From Kaines machine we tested the gateway script making some minor adjustments where needed to fix any typod and the gateway script seemed to work fine. It setup the iptables and suceeded without errors.
    However, we did then notice then when we tried to test one of the other machines they did not seem to be able to access the internet through the gateway so the gateway has an issue we have not yet detected.
    We have confirmed that the systems are having their gateway set to the 10.0.0.1 ip by the dhcp so that is not the issue.

    We decided to take a break from the gateway script and try to test the dns script instead.

    We ran the dns script on kaines vm and after tourbleshooting some syntax errors which were stopping the server from running we got the server up and running fine.
    The main issue we then run into was the search domain was still defaulting to easlab.co.uk even though the systems were having the domain search easlab.local set by the dhcp.

    The issue turned out to be that because we were testing the DNS on a different system that we will be running it on officially then the dhcp was not pointing everyone to the correct DNS system, after updating the dhcp with the temp change we coudl confirm that the dns was working.

    I then reverted the dhcp back to it's correct value form the temp one set for testing purposes.

    After returning to the gateway we discovered that the script appeared to be skipping over some of the ip table commands, we are not wntirely sure which ones or why but running the gateway script twice seems to ensure that all commands are run corrcetly and this resolved the gaeway issue. All system now had access to the internet through the gateway and so the DNS script was able to install the required packages.

    With all 3 of the main service scripts now able to run we had dynamic IP range being set, the DNS resolving hostnames and the gateway passing traffic through to outside the network.

    Next we ran into an issue we noticed with the search domain the ingress and egress systems were using. Where the DHCP was setting the search domain to easlab.local and the 3 internal segragated systems were using that so they could ping via the app hostnames the 2 end systems were by default prioritising the easlab.co.uk search domains. It took us quite a while to figure out how to resolve this and it did come with some assistance and pointers from Rhys.
    
    The solution eneded up being to force their external network interface to ignore DNS traffic so that it would run through the segregated network interface instead.
    This was achived with this command:
nmcli con mod "Wired connection 1" ipv4.ignore-auto-dns yes
nmcli con down "Wired connection 1"
nmcli con up "Wired connection 1"
    This set the network intreface to ignore the DNS traffic and allow the segragated network interface to take over.
    With this in place all systems could now ping using the app hostnames.

    With most things working and each of the scripts tested individually the master script was written up so that 1 script could be called and it would handdle the running of each of the service scripts on their designated machines.
    Once someone runs the master script it will go through each task 1 at a time, promting the user evertime it wants to ssh to a new machine to perform it's function.

    With that the DHCP, DNS and Gateway scripts can now be run from 1 script and a user wishing to use this only needs to keep track of and run the 1 script and that master script will handle everything else.

    Next we moved on to runnign the HTTP-Server on max's machine and having each of the other systems pull the apps down and run them.

    We decided that as the apps would need to be edited anyways it was easier to simply have everyone pull down app1 and just edit the index acordingly.

    We ran into some errors with the HTTP-Server where the firewalls were blocking the traffic so an exception in the firewall command was added to the script to allow the traffic through.

    With that in place the script was now able to pull app1 on to each system, unzip it and then edit the index.js with the code required by each app.

    When trying to run the apps however we have now run into an issue where the apps will not successfully run in the background. We have the:
node index.js &
    which should be running the app in the background but for some reason when running from a script like this it seems to run in the foreground regardless meaning we are unable to get all of the apps running from the master script.

    After some troubleshooting we managed to find a method to force the apps to run in the background. we could use the forever flag to make the apps run forever in the background.
    By adding
npm install -g forever
    each of the systems will install that tool and then we could run the apps with
forever start index.js
    Made forced the apps to run in the background and allowed the msater script to move on while leaving the apps running on each machine.

    We originally ran into an issue with the npm install and discovered that it was tied to the dns ignore that was being set on the ingress and egress and was breaking the gateways passthrough to the internet so we have removed that for now and are getting the ingress system to run the app with the direct ip rather than the host name to test and intend to find a new solution to the hostname issue with the ingress and egress systems.

    We decided to move away from the scripts and try testing the apps manually for the sake of debugging, this helped us to prove that the forever command we decided to try using did not work as we though, instead of keeping the app running in the background it actually seemed to repeatadly re-run the app over and over again. This was not ideal for our situation.
    We removed the forever command and went back to just running the apps in the background with the & sybol.

    It was at this point we discovered that although the apps would appear to run in the foreground and require us to ^C the apps they would actually continue to run in the background. This is honestly a wierd situation that I do not fully understand but at least I now know exactly what is happening.

    We went back to running and testting the apps manually so we could debug the app link errors.
    After a little back and fourth with the error messages we discoved that it was a firewall error with the port.
firewall-cmd --permanent --add-port=80/tcp
firewall-cmd --reload
    Running these commands allowed an acception through the firewall on the port that the apps are using.
    With all apps running manually and each system running this firewall command we tested the apps and found they were now working as intended.

    We decided to debug running the apps from scripts again but didn't want to have to run everything from the master script every time so we ran the masterscript setting up the DHCP, DNS and Gateways without the apps and created snapshots of the vms at these points.
    This allowed us to only have to run the app scripts after a snapshot reset which is a lot smoother and quicker.

    At this point we made a appTroubleshoot script that was being used instead of the master script to run only the app scripts for testing purposes.

    The app scripts each had the previous firewall acception command added to them before the scripts run the apps.
    Apps 2-5 could now be run in the background from the scrips but app1 seems to be skipped over regardless of how we attempt to run it in the script.
    If we run app 1 manually then we can confirm that all the apps are working correctly now even when being run from the scrips.

    At this point we decided to merge the updated apps scripts calls from the appsTroublshoot script and back into the master.
    We reset the vms back to their initial snapshots and tested the master script in its entirety.

    Again app1 is not being run so that needs to be run manually at the end but everything else, that is to say the DHCP, DNS, Gateway and aps 2-5 all get settup and run correctly and the chain through the apps works fine.

    Over the weekend Kalem had discoved a more commonly used alternative to the forever service called PM2, PM2 seemed to be a more up to date version of forever with some better functionality.

    Installing and implementing PM2 in the same we we did forever earlier in the task allowed us to daemonise and run app1.
npm install pm2 -g
pm2 start app1/index.js
    With app1 now running in background from script and not needing to be run manually the task is complete.
    A single script can be run through to complete the entire task.


    Improvements to remove user input:
    One of the main issues we had requiring user input was when running ssh on a new connection first time, the user would be asked for the authentication and the user would have to input yes, this could be avoided with the following flag added to the ssh command
-oStrictHostKeyChecking=no
    With that flag added to the ssh the key checking would be bypassed and the user will be asked for the password regardless of whether it is the first time connecting or not.

    The next major issue is the passwords. Whenever an ssh connection was made the user would be promted to input the password. A simple solution to this would be to add a user input for the password request at the top of the script and to store that input in a variable, then whenever the password is requested the script could simply input the password from the saved variabel.
read -s password
    By adding the -s flag the users input will also be hidden from the terminal like with other linux password inputs.

    The final user input that was required by our script was with the file server and the apps. Even though they were succesfully being run in the background they will still display the foreground proccess requiring the user to ctrl+c out of them (The background process would remain running). One possible fix to this would be to use a trap command to trap the exit signal and then use that to exit the apps but a better way would be to solve the problem and not have them display in the foreground at all. We could use the PM2 command that was discovered for app1's not running problem and use that to daemnonise the proccesses in the same way and have them run as services. With this the user would not need to ctrl+c out of them at all.

    With these changes the only user interaction that would be required now would be the user going into the system, pulling the scripts from git and running it and then the first act of the script asking the user for the password that will be used for the rest of the connections, Once the user has entered that password once the script should run through to completeing without the user being asked for anymore inputs.


    Solution Testing:
-oStrictHostKeyChecking=no
    I tested the key checking no command and this worked as expected, this bypassed the request for a key check negating the need for a user input on this section.

    I was able to use sshpass to pass in the file variable to the ssh connection. Mac by default does not allow users to download sshpass but this shouldn't be a problem with most linux distributions. I was able to manually install sshpass to test this out and then used the:
read -s password
    command mentioned above. This asked the user for the password at the start of the script once and can then be passed in to the ssh connection via a variable with sshpass
sshpass -p $password ssh root@hostname

    Running the http-server in the background was solved in the same way app1 was solved, using the pm2 package I could simply run the http-server with that to daemonise it and run it removing the need for the user to ctrl+c out
pm2 start http-server

    After further testing I also managed to get the expect method working.
    You can run an expect in one line with the -c flag
expect -c "spawn ssh root@hostname; expect \"password:\"; send \"$password\r\"; interact"
    This will run the ssh command and expect a password request, the send then populates that expect with the given string, using the $ you can pass in a variable instead.

sshpass -p $password ssh root@192.168.1.173 -oStrictHostKeyChecking=no "pkill http-server; npm install pm2 -g; pm2 start http-server; echo 'server running'"
    This is full command run in the bash file that can ssh into the system with the password through sshpass, then make sure no other http-server is running, ensures pm2 is installed, runs the http-server daemonised with pm2 and finally echos out 'server running' to show that more commands can be run without further user input needed, then the ssh connection finishes.